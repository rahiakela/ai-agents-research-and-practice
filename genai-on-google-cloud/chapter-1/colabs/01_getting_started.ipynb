{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Getting Started with Gemini 3 on Vertex AI\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ayoisio/genai-on-google-cloud/blob/main/chapter-1/colabs/01_getting_started.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides a quick environment check to ensure you can successfully connect to Vertex AI and generate responses with Gemini 3. Use this as a warm-up before diving into Chapter 2's more complex exercises.\n",
    "\n",
    "**Learning Goals:**\n",
    "- Verify your Google Cloud project setup\n",
    "- Use the Google Gen AI SDK for Python\n",
    "- Make your first API call to Gemini 3\n",
    "- Understand the basic response structure\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- A Google Cloud project with billing enabled\n",
    "- Vertex AI API enabled\n",
    "- Authentication configured (Colab handles this automatically)\n",
    "\n",
    "> **See also**: [Official Gemini 3 Getting Started Notebooks](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/getting-started)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Setup: Install packages and authenticate\n",
    "# Install the Google Gen AI SDK (version 1.56.0 or later required for Gemini 3)\n",
    "!pip install -U google-genai -q\n",
    "\n",
    "# Authenticate (required in Colab)\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Configuration: Set your project details\n",
    "PROJECT_ID = \"your-project-id\"  # @param {type:\"string\"}\n",
    "LOCATION = \"global\"  # @param {type:\"string\"}\n",
    "\n",
    "# Initialize the Gen AI client with Vertex AI\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "print(f\"Initialized Gen AI client with project: {PROJECT_ID}, location: {LOCATION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your First Gemini 3 Request\n",
    "\n",
    "Let's make a simple request to Gemini 3 to verify everything is working. We'll use `gemini-3-flash-preview` - Google's latest fast, efficient model with thinking capabilities.\n",
    "\n",
    "**Key feature**: Gemini 3 models support `thinking_config` to control reasoning depth:\n",
    "- `MINIMAL` - Fastest responses, minimal reasoning\n",
    "- `LOW` / `MEDIUM` / `HIGH` - Increasing reasoning depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model ID for Gemini 3 Flash\n",
    "MODEL_ID = \"gemini-3-flash-preview\"\n",
    "\n",
    "# Make a simple request with minimal thinking (fastest)\n",
    "prompt = \"Explain what a Large Language Model (LLM) is in exactly 3 sentences.\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=prompt,\n",
    "    config=types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(\n",
    "            thinking_level=types.ThinkingLevel.MINIMAL\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"\\nResponse:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success!\n",
    "\n",
    "If you see a response above, your environment is correctly configured. You're ready to proceed to **Chapter 2: Data Readiness and Accessibility**, where you'll learn about RAG (Retrieval-Augmented Generation) and grounding LLM responses with external data.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Google Gen AI SDK** (`google-genai`) is the recommended SDK for Gemini 3\n",
    "- **`genai.Client`** with `vertexai=True` connects to Vertex AI\n",
    "- **`thinking_config`** controls reasoning depth vs. speed tradeoff\n",
    "- **Model selection**: `gemini-3-flash-preview` for speed, `gemini-3-pro-preview` for complex reasoning\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Try the [official Gemini 3 notebooks](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/getting-started)\n",
    "2. Explore the [Google Gen AI SDK documentation](https://googleapis.github.io/python-genai/)\n",
    "3. Proceed to [Chapter 2](../../chapter-2/) for hands-on RAG implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration with BigQuery\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ayoisio/genai-on-google-cloud/blob/main/chapter-2/colabs/01_data_exploration_bigquery.ipynb)\n",
    "\n",
    "**Estimated Time**: 10-15 minutes\n",
    "\n",
    "**Prerequisites**: Google Cloud project with billing enabled, BigQuery API enabled\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "Before building LLM applications, you need to understand your data. This notebook demonstrates how to:\n",
    "\n",
    "1. **Explore datasets** using BigQuery's INFORMATION_SCHEMA\n",
    "2. **Assess data quality** with profiling queries\n",
    "3. **Understand data structure** for LLM readiness\n",
    "\n",
    "These foundational skills are essential for the data readiness concepts covered in Chapter 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Install Dependencies\n",
    "!pip install --upgrade google-cloud-bigquery google-cloud-aiplatform -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Authenticate with Google Cloud\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "print(\"âœ“ Authentication successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Configure Your Project\n",
    "PROJECT_ID = \"your-project-id\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "# Validate project ID\n",
    "if PROJECT_ID == \"your-project-id\":\n",
    "    raise ValueError(\"Please set your PROJECT_ID above\")\n",
    "\n",
    "print(f\"âœ“ Project: {PROJECT_ID}\")\n",
    "print(f\"âœ“ Location: {LOCATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Initialize BigQuery Client\n",
    "from google.cloud import bigquery\n",
    "\n",
    "bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "print(f\"âœ“ BigQuery client initialized for project: {PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring Public Datasets\n",
    "\n",
    "BigQuery provides access to many public datasets that are ideal for experimentation. Let's explore the Wikipedia dataset, which is commonly used for NLP and LLM applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title List tables in a public dataset\n",
    "DATASET_ID = \"bigquery-public-data.samples\"\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    table_name,\n",
    "    table_type,\n",
    "    creation_time,\n",
    "    ROUND(size_bytes / 1024 / 1024, 2) as size_mb\n",
    "FROM `bigquery-public-data.samples.INFORMATION_SCHEMA.TABLES`\n",
    "ORDER BY size_bytes DESC\n",
    "\"\"\"\n",
    "\n",
    "tables_df = bq_client.query(query).to_dataframe()\n",
    "print(f\"Found {len(tables_df)} tables in {DATASET_ID}:\\n\")\n",
    "display(tables_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Examine table schema\n",
    "TABLE_ID = \"wikipedia\"  # @param {type:\"string\"}\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    column_name,\n",
    "    data_type,\n",
    "    is_nullable\n",
    "FROM `bigquery-public-data.samples.INFORMATION_SCHEMA.COLUMNS`\n",
    "WHERE table_name = '{TABLE_ID}'\n",
    "ORDER BY ordinal_position\n",
    "\"\"\"\n",
    "\n",
    "schema_df = bq_client.query(query).to_dataframe()\n",
    "print(f\"Schema for {TABLE_ID}:\\n\")\n",
    "display(schema_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Preview sample data\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    title,\n",
    "    SUBSTR(text, 1, 200) as text_preview,\n",
    "    LENGTH(text) as text_length\n",
    "FROM `bigquery-public-data.samples.wikipedia`\n",
    "WHERE text IS NOT NULL\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "sample_df = bq_client.query(query).to_dataframe()\n",
    "print(\"Sample Wikipedia articles:\\n\")\n",
    "display(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment\n",
    "\n",
    "Understanding data quality is crucial for LLM applications. Poor quality data leads to poor model outputs (\"Garbage In, Garbage Out\"). Let's assess key quality dimensions:\n",
    "\n",
    "- **Completeness**: How much data is missing?\n",
    "- **Consistency**: Are values within expected ranges?\n",
    "- **Distribution**: What does the data look like statistically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Check data completeness (null values)\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    COUNT(*) as total_rows,\n",
    "    COUNTIF(title IS NULL) as null_titles,\n",
    "    COUNTIF(text IS NULL) as null_text,\n",
    "    COUNTIF(text IS NULL OR LENGTH(text) = 0) as empty_text,\n",
    "    ROUND(COUNTIF(text IS NOT NULL AND LENGTH(text) > 0) * 100.0 / COUNT(*), 2) as completeness_pct\n",
    "FROM `bigquery-public-data.samples.wikipedia`\n",
    "\"\"\"\n",
    "\n",
    "quality_df = bq_client.query(query).to_dataframe()\n",
    "print(\"Data Completeness Analysis:\\n\")\n",
    "display(quality_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Analyze text length distribution\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    MIN(LENGTH(text)) as min_length,\n",
    "    MAX(LENGTH(text)) as max_length,\n",
    "    ROUND(AVG(LENGTH(text)), 0) as avg_length,\n",
    "    APPROX_QUANTILES(LENGTH(text), 4)[OFFSET(2)] as median_length,\n",
    "    APPROX_QUANTILES(LENGTH(text), 100)[OFFSET(90)] as p90_length,\n",
    "    APPROX_QUANTILES(LENGTH(text), 100)[OFFSET(99)] as p99_length\n",
    "FROM `bigquery-public-data.samples.wikipedia`\n",
    "WHERE text IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "length_df = bq_client.query(query).to_dataframe()\n",
    "print(\"Text Length Distribution:\\n\")\n",
    "display(length_df)\n",
    "\n",
    "print(\"\\nðŸ’¡ Tip: Understanding text length helps determine chunking strategies for RAG.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Create a data profiling summary\n",
    "query = \"\"\"\n",
    "WITH text_stats AS (\n",
    "    SELECT\n",
    "        LENGTH(text) as text_length,\n",
    "        ARRAY_LENGTH(SPLIT(text, ' ')) as word_count\n",
    "    FROM `bigquery-public-data.samples.wikipedia`\n",
    "    WHERE text IS NOT NULL AND LENGTH(text) > 0\n",
    ")\n",
    "SELECT\n",
    "    'Total Documents' as metric,\n",
    "    CAST(COUNT(*) as STRING) as value\n",
    "FROM text_stats\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'Avg Words per Document',\n",
    "    CAST(ROUND(AVG(word_count), 0) as STRING)\n",
    "FROM text_stats\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'Avg Characters per Document',\n",
    "    CAST(ROUND(AVG(text_length), 0) as STRING)\n",
    "FROM text_stats\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'Documents > 10K chars',\n",
    "    CAST(COUNTIF(text_length > 10000) as STRING)\n",
    "FROM text_stats\n",
    "\"\"\"\n",
    "\n",
    "profile_df = bq_client.query(query).to_dataframe()\n",
    "print(\"ðŸ“Š Data Profile Summary:\\n\")\n",
    "display(profile_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identifying LLM-Ready Data\n",
    "\n",
    "Not all data is suitable for LLM applications. Let's identify documents that meet quality thresholds for RAG or fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Find high-quality documents for LLM use\n",
    "MIN_WORDS = 100  # @param {type:\"integer\"}\n",
    "MAX_WORDS = 5000  # @param {type:\"integer\"}\n",
    "\n",
    "query = f\"\"\"\n",
    "WITH document_analysis AS (\n",
    "    SELECT\n",
    "        title,\n",
    "        text,\n",
    "        LENGTH(text) as char_count,\n",
    "        ARRAY_LENGTH(SPLIT(text, ' ')) as word_count\n",
    "    FROM `bigquery-public-data.samples.wikipedia`\n",
    "    WHERE text IS NOT NULL AND LENGTH(text) > 0\n",
    ")\n",
    "SELECT\n",
    "    title,\n",
    "    word_count,\n",
    "    char_count,\n",
    "    SUBSTR(text, 1, 150) as text_preview\n",
    "FROM document_analysis\n",
    "WHERE word_count BETWEEN {MIN_WORDS} AND {MAX_WORDS}\n",
    "ORDER BY word_count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "quality_docs_df = bq_client.query(query).to_dataframe()\n",
    "print(f\"ðŸ“ Documents with {MIN_WORDS}-{MAX_WORDS} words (ideal for RAG):\\n\")\n",
    "display(quality_docs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Summarize LLM readiness\n",
    "query = f\"\"\"\n",
    "WITH document_analysis AS (\n",
    "    SELECT\n",
    "        ARRAY_LENGTH(SPLIT(text, ' ')) as word_count\n",
    "    FROM `bigquery-public-data.samples.wikipedia`\n",
    "    WHERE text IS NOT NULL AND LENGTH(text) > 0\n",
    ")\n",
    "SELECT\n",
    "    COUNT(*) as total_documents,\n",
    "    COUNTIF(word_count < {MIN_WORDS}) as too_short,\n",
    "    COUNTIF(word_count BETWEEN {MIN_WORDS} AND {MAX_WORDS}) as ideal_length,\n",
    "    COUNTIF(word_count > {MAX_WORDS}) as too_long,\n",
    "    ROUND(COUNTIF(word_count BETWEEN {MIN_WORDS} AND {MAX_WORDS}) * 100.0 / COUNT(*), 2) as ideal_pct\n",
    "FROM document_analysis\n",
    "\"\"\"\n",
    "\n",
    "readiness_df = bq_client.query(query).to_dataframe()\n",
    "print(\"ðŸŽ¯ LLM Readiness Summary:\\n\")\n",
    "display(readiness_df)\n",
    "\n",
    "ideal_pct = readiness_df['ideal_pct'].iloc[0]\n",
    "print(f\"\\nâœ… {ideal_pct}% of documents are in the ideal length range for RAG applications.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Try It Yourself\n",
    "\n",
    "Now it's your turn! Modify the queries below to explore different aspects of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a query to find the top 10 longest Wikipedia articles\n",
    "# Hint: Use ORDER BY with LENGTH(text) DESC\n",
    "\n",
    "your_query = \"\"\"\n",
    "-- Your query here\n",
    "SELECT \n",
    "    title,\n",
    "    LENGTH(text) as text_length\n",
    "FROM `bigquery-public-data.samples.wikipedia`\n",
    "WHERE text IS NOT NULL\n",
    "ORDER BY LENGTH(text) DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result_df = bq_client.query(your_query).to_dataframe()\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Explore a different public dataset\n",
    "# Try: bigquery-public-data.patents_view.patent\n",
    "\n",
    "explore_query = \"\"\"\n",
    "SELECT \n",
    "    table_name,\n",
    "    ROUND(size_bytes / 1024 / 1024 / 1024, 2) as size_gb\n",
    "FROM `bigquery-public-data.patents_view.INFORMATION_SCHEMA.TABLES`\n",
    "ORDER BY size_bytes DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "result_df = bq_client.query(explore_query).to_dataframe()\n",
    "print(\"Patents dataset tables:\")\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "\n",
    "1. âœ… **Explore datasets** using BigQuery's INFORMATION_SCHEMA\n",
    "2. âœ… **Assess data quality** with completeness and distribution checks\n",
    "3. âœ… **Identify LLM-ready data** based on quality thresholds\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Data profiling** is essential before building LLM applications\n",
    "- **Text length analysis** helps determine chunking strategies for RAG\n",
    "- **BigQuery public datasets** provide excellent experimentation data\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue to the next notebook: **[02_document_processing.ipynb](02_document_processing.ipynb)** to learn how to extract structured data from unstructured documents using Document AI."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

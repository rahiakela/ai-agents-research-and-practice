{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Processing for LLM Applications\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ayoisio/genai-on-google-cloud/blob/main/chapter-2/colabs/02_document_processing.ipynb)\n",
    "\n",
    "**Estimated Time**: 15 minutes\n",
    "\n",
    "**Prerequisites**: Google Cloud project with billing enabled, Vertex AI API enabled\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "Unstructured documents (PDFs, images, scanned files) contain valuable knowledge for LLM applications. This notebook demonstrates how to:\n",
    "\n",
    "1. **Process documents** using Gemini's multimodal capabilities\n",
    "2. **Extract structured data** from unstructured content\n",
    "3. **Prepare documents** for RAG pipelines\n",
    "\n",
    "We'll also cover the BigQuery + Document AI pattern for enterprise-scale processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Install Dependencies\n",
    "!pip install --upgrade google-cloud-aiplatform google-generativeai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Authenticate with Google Cloud\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "print(\"‚úì Authentication successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Configure Your Project\n",
    "PROJECT_ID = \"your-project-id\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "# Validate project ID\n",
    "if PROJECT_ID == \"your-project-id\":\n",
    "    raise ValueError(\"Please set your PROJECT_ID above\")\n",
    "\n",
    "print(f\"‚úì Project: {PROJECT_ID}\")\n",
    "print(f\"‚úì Location: {LOCATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Initialize Vertex AI\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "print(f\"‚úì Vertex AI initialized for project: {PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Document Processing with Gemini\n\nGemini's multimodal capabilities allow direct processing of documents without OCR preprocessing. This is ideal for:\n- Quick document analysis\n- Extracting key information\n- Summarization for RAG\n\n```mermaid\nflowchart LR\n    A[PDF/Image] --> B[Gemini]\n    B --> C[Extract]\n    C --> D[Chunk]\n    D --> E[Output]\n```\n\nLet's process a sample PDF document."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Load a sample document from Cloud Storage\n",
    "# Using a public sample document\n",
    "SAMPLE_PDF_URI = \"gs://cloud-samples-data/generative-ai/pdf/2312.11805v3.pdf\"\n",
    "\n",
    "# Create a Part from the PDF URI\n",
    "pdf_file = Part.from_uri(SAMPLE_PDF_URI, mime_type=\"application/pdf\")\n",
    "\n",
    "print(f\"‚úì Loaded document: {SAMPLE_PDF_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Extract document summary\n",
    "model = GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "prompt = \"\"\"\n",
    "Analyze this document and provide:\n",
    "1. A brief summary (2-3 sentences)\n",
    "2. Key topics covered\n",
    "3. Main findings or conclusions\n",
    "\n",
    "Format your response as structured text.\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content([pdf_file, prompt])\n",
    "\n",
    "print(\"üìÑ Document Analysis:\\n\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Extract structured data from the document\n",
    "extraction_prompt = \"\"\"\n",
    "Extract the following information from this document and return it as JSON:\n",
    "\n",
    "{\n",
    "    \"title\": \"document title\",\n",
    "    \"authors\": [\"list of authors\"],\n",
    "    \"abstract\": \"brief abstract or summary\",\n",
    "    \"key_terms\": [\"important technical terms\"],\n",
    "    \"document_type\": \"research paper/report/manual/etc\"\n",
    "}\n",
    "\n",
    "Return only valid JSON, no additional text.\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content([pdf_file, extraction_prompt])\n",
    "\n",
    "print(\"üìã Extracted Structured Data:\\n\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Parse the JSON response\n",
    "import json\n",
    "\n",
    "try:\n",
    "    # Clean up the response (remove markdown code blocks if present)\n",
    "    json_text = response.text.strip()\n",
    "    if json_text.startswith(\"```json\"):\n",
    "        json_text = json_text[7:]\n",
    "    if json_text.startswith(\"```\"):\n",
    "        json_text = json_text[3:]\n",
    "    if json_text.endswith(\"```\"):\n",
    "        json_text = json_text[:-3]\n",
    "    \n",
    "    extracted_data = json.loads(json_text.strip())\n",
    "    \n",
    "    print(\"‚úÖ Successfully parsed structured data:\")\n",
    "    print(f\"\\nTitle: {extracted_data.get('title', 'N/A')}\")\n",
    "    print(f\"Authors: {', '.join(extracted_data.get('authors', []))}\")\n",
    "    print(f\"Type: {extracted_data.get('document_type', 'N/A')}\")\n",
    "    print(f\"Key Terms: {', '.join(extracted_data.get('key_terms', [])[:5])}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"‚ö†Ô∏è Could not parse JSON: {e}\")\n",
    "    print(\"Raw response:\", response.text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chunking Documents for RAG\n",
    "\n",
    "For RAG applications, documents need to be split into smaller chunks. Let's extract content and create chunks suitable for embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Extract full text content from document\n",
    "text_extraction_prompt = \"\"\"\n",
    "Extract all the text content from this document, preserving the structure.\n",
    "Include section headers and maintain paragraph breaks.\n",
    "Return only the extracted text, no commentary.\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content([pdf_file, text_extraction_prompt])\n",
    "full_text = response.text\n",
    "\n",
    "print(f\"üìù Extracted {len(full_text)} characters from document\")\n",
    "print(f\"\\nFirst 500 characters:\\n{full_text[:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Implement simple chunking strategy\n",
    "def chunk_text(text, chunk_size=1000, overlap=200):\n",
    "    \"\"\"\n",
    "    Split text into overlapping chunks.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to chunk\n",
    "        chunk_size: Target size of each chunk in characters\n",
    "        overlap: Number of overlapping characters between chunks\n",
    "    \n",
    "    Returns:\n",
    "        List of text chunks\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(text):\n",
    "        # Find end of chunk\n",
    "        end = start + chunk_size\n",
    "        \n",
    "        # Try to break at a sentence boundary\n",
    "        if end < len(text):\n",
    "            # Look for sentence endings near the chunk boundary\n",
    "            for sep in ['. ', '\\n\\n', '\\n', ' ']:\n",
    "                boundary = text.rfind(sep, start + chunk_size - 100, end + 100)\n",
    "                if boundary != -1:\n",
    "                    end = boundary + len(sep)\n",
    "                    break\n",
    "        \n",
    "        chunk = text[start:end].strip()\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "        \n",
    "        # Move start position with overlap\n",
    "        start = end - overlap\n",
    "        if start >= len(text):\n",
    "            break\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Create chunks\n",
    "CHUNK_SIZE = 1000  # @param {type:\"integer\"}\n",
    "OVERLAP = 200  # @param {type:\"integer\"}\n",
    "\n",
    "chunks = chunk_text(full_text, chunk_size=CHUNK_SIZE, overlap=OVERLAP)\n",
    "\n",
    "print(f\"üì¶ Created {len(chunks)} chunks from the document\\n\")\n",
    "print(\"Chunk sizes:\")\n",
    "for i, chunk in enumerate(chunks[:5]):\n",
    "    print(f\"  Chunk {i+1}: {len(chunk)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Preview chunks\n",
    "print(\"üìÑ Sample Chunks:\\n\")\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"--- Chunk {i+1} ({len(chunk)} chars) ---\")\n",
    "    print(chunk[:300] + \"...\" if len(chunk) > 300 else chunk)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Enterprise Pattern: BigQuery + Document AI\n",
    "\n",
    "For enterprise-scale document processing, Google Cloud provides the BigQuery + Document AI integration. This pattern enables:\n",
    "\n",
    "- **Scalable processing** of thousands of documents\n",
    "- **SQL-based access** to extracted data\n",
    "- **Integration** with existing data pipelines\n",
    "\n",
    "Here's the pattern (requires Document AI processor setup):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title BigQuery + Document AI Pattern (Reference)\n",
    "# This is a reference pattern - requires Document AI processor setup\n",
    "\n",
    "BIGQUERY_DOCUMENT_AI_PATTERN = '''\n",
    "-- Step 1: Create an external connection to Vertex AI\n",
    "-- (Run this in BigQuery console or using bq command)\n",
    "-- CREATE EXTERNAL CONNECTION `{PROJECT_ID}.{LOCATION}.docai_connection`\n",
    "-- OPTIONS(type = 'CLOUD_RESOURCE');\n",
    "\n",
    "-- Step 2: Create an object table pointing to your documents\n",
    "CREATE OR REPLACE EXTERNAL TABLE `{PROJECT_ID}.{DATASET}.documents_table`\n",
    "WITH CONNECTION `{PROJECT_ID}.{LOCATION}.docai_connection`\n",
    "OPTIONS (\n",
    "    object_metadata = 'SIMPLE',\n",
    "    uris = ['gs://your-bucket/documents/*']\n",
    ");\n",
    "\n",
    "-- Step 3: Create a remote model for Document AI\n",
    "CREATE OR REPLACE MODEL `{PROJECT_ID}.{DATASET}.docai_model`\n",
    "REMOTE WITH CONNECTION `{PROJECT_ID}.{LOCATION}.docai_connection`\n",
    "OPTIONS (\n",
    "    remote_service_type = 'CLOUD_AI_DOCUMENT_V1',\n",
    "    document_processor = 'projects/{PROJECT_ID}/locations/us/processors/{PROCESSOR_ID}'\n",
    ");\n",
    "\n",
    "-- Step 4: Process documents with ML.PROCESS_DOCUMENT\n",
    "SELECT\n",
    "    uri,\n",
    "    ml_process_document_result,\n",
    "    ml_process_document_status\n",
    "FROM ML.PROCESS_DOCUMENT(\n",
    "    MODEL `{PROJECT_ID}.{DATASET}.docai_model`,\n",
    "    TABLE `{PROJECT_ID}.{DATASET}.documents_table`\n",
    ");\n",
    "'''\n",
    "\n",
    "print(\"üìã BigQuery + Document AI Pattern:\")\n",
    "print(BIGQUERY_DOCUMENT_AI_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Example 2-1 from Chapter: Contract Processing SQL\n",
    "# This is the SQL pattern from the chapter for processing contracts\n",
    "\n",
    "CHAPTER_EXAMPLE = '''\n",
    "-- Example 2-1: Process contracts with Document AI and join with client data\n",
    "-- This pattern enables direct SQL queries over unstructured documents\n",
    "\n",
    "WITH processed_contracts AS (\n",
    "    SELECT\n",
    "        uri AS contract_path,\n",
    "        JSON_EXTRACT_SCALAR(ml_process_document_result, '$.document.entities[0].mentionText') AS contract_id,\n",
    "        JSON_EXTRACT_SCALAR(ml_process_document_result, '$.document.entities[1].mentionText') AS client_name,\n",
    "        JSON_EXTRACT_SCALAR(ml_process_document_result, '$.document.entities[2].mentionText') AS contract_value,\n",
    "        JSON_EXTRACT_SCALAR(ml_process_document_result, '$.document.entities[3].mentionText') AS effective_date\n",
    "    FROM ML.PROCESS_DOCUMENT(\n",
    "        MODEL `project.dataset.contract_parser_model`,\n",
    "        TABLE `project.dataset.contracts_object_table`\n",
    "    )\n",
    "    WHERE ml_process_document_status = ''\n",
    ")\n",
    "SELECT\n",
    "    c.contract_id,\n",
    "    c.client_name,\n",
    "    c.contract_value,\n",
    "    c.effective_date,\n",
    "    cl.client_segment,\n",
    "    cl.account_manager\n",
    "FROM processed_contracts c\n",
    "JOIN `project.dataset.clients` cl\n",
    "    ON c.client_name = cl.client_name;\n",
    "'''\n",
    "\n",
    "print(\"üìã Example 2-1: Contract Processing with Document AI:\")\n",
    "print(CHAPTER_EXAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preparing Documents for RAG\n",
    "\n",
    "Let's create a complete document processing pipeline that prepares content for a RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Create RAG-ready document structure\n",
    "from datetime import datetime\n",
    "\n",
    "def prepare_for_rag(chunks, document_uri, metadata=None):\n",
    "    \"\"\"\n",
    "    Prepare document chunks for a RAG system.\n",
    "    \n",
    "    Args:\n",
    "        chunks: List of text chunks\n",
    "        document_uri: Source document URI\n",
    "        metadata: Optional document metadata\n",
    "    \n",
    "    Returns:\n",
    "        List of RAG-ready document objects\n",
    "    \"\"\"\n",
    "    rag_documents = []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        doc = {\n",
    "            \"id\": f\"{document_uri.split('/')[-1]}_{i}\",\n",
    "            \"content\": chunk,\n",
    "            \"source\": document_uri,\n",
    "            \"chunk_index\": i,\n",
    "            \"total_chunks\": len(chunks),\n",
    "            \"char_count\": len(chunk),\n",
    "            \"processed_at\": datetime.now().isoformat(),\n",
    "            \"metadata\": metadata or {}\n",
    "        }\n",
    "        rag_documents.append(doc)\n",
    "    \n",
    "    return rag_documents\n",
    "\n",
    "# Prepare our chunks for RAG\n",
    "rag_docs = prepare_for_rag(\n",
    "    chunks,\n",
    "    SAMPLE_PDF_URI,\n",
    "    metadata=extracted_data if 'extracted_data' in dir() else {}\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Prepared {len(rag_docs)} documents for RAG\\n\")\n",
    "print(\"Sample document structure:\")\n",
    "print(json.dumps(rag_docs[0], indent=2, default=str)[:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Save processed documents (for use in next notebooks)\n",
    "import json\n",
    "\n",
    "# Save to a JSON file\n",
    "output_file = \"/content/processed_documents.json\"\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(rag_docs, f, indent=2, default=str)\n",
    "\n",
    "print(f\"‚úÖ Saved {len(rag_docs)} documents to {output_file}\")\n",
    "print(f\"\\nThis file can be used in the next notebooks for:\")\n",
    "print(\"  - Generating embeddings\")\n",
    "print(\"  - Building vector search indexes\")\n",
    "print(\"  - RAG context assembly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Try It Yourself\n",
    "\n",
    "Experiment with different document processing approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Process a different type of document\n",
    "# Try an image document instead of PDF\n",
    "\n",
    "IMAGE_URI = \"gs://cloud-samples-data/generative-ai/image/scones.jpg\"\n",
    "\n",
    "image_part = Part.from_uri(IMAGE_URI, mime_type=\"image/jpeg\")\n",
    "\n",
    "image_prompt = \"\"\"\n",
    "Describe this image in detail. Include:\n",
    "1. What you see\n",
    "2. Any text visible in the image\n",
    "3. Key elements that would be useful for search\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content([image_part, image_prompt])\n",
    "print(\"üñºÔ∏è Image Analysis:\\n\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Experiment with different chunk sizes\n",
    "# Try smaller chunks for more granular retrieval\n",
    "\n",
    "small_chunks = chunk_text(full_text, chunk_size=500, overlap=100)\n",
    "large_chunks = chunk_text(full_text, chunk_size=2000, overlap=400)\n",
    "\n",
    "print(f\"Chunk size comparison:\")\n",
    "print(f\"  Small (500 chars): {len(small_chunks)} chunks\")\n",
    "print(f\"  Medium (1000 chars): {len(chunks)} chunks\")\n",
    "print(f\"  Large (2000 chars): {len(large_chunks)} chunks\")\n",
    "print(f\"\\nüí° Smaller chunks = more precise retrieval but more API calls\")\n",
    "print(f\"üí° Larger chunks = more context but may include irrelevant info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "\n",
    "1. ‚úÖ **Process documents** using Gemini's multimodal capabilities\n",
    "2. ‚úÖ **Extract structured data** from unstructured content\n",
    "3. ‚úÖ **Chunk documents** for RAG pipelines\n",
    "4. ‚úÖ **Understand the BigQuery + Document AI pattern** for enterprise scale\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Gemini multimodal** enables quick document processing without OCR setup\n",
    "- **Chunking strategy** significantly impacts RAG quality\n",
    "- **BigQuery + Document AI** scales to thousands of documents\n",
    "- **Structured extraction** enables hybrid search (semantic + keyword)\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue to the next notebook: **[03_embeddings_vector_search.ipynb](03_embeddings_vector_search.ipynb)** to learn how to generate embeddings and perform semantic search on your processed documents."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enterprise RAG Knowledge Engine\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ayoisio/genai-on-google-cloud/blob/main/chapter-2/colabs/06_enterprise_rag_knowledge_engine.ipynb)\n",
    "\n",
    "**Estimated Time**: 45-60 minutes\n",
    "\n",
    "**Prerequisites**: Google Cloud project with billing enabled, BigQuery, Cloud SQL, and Vertex AI APIs enabled\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates building a **production-ready Enterprise RAG Knowledge Engine** that combines:\n",
    "\n",
    "### Part 1: BigQuery-Native RAG Pipeline\n",
    "1. **Unstructured-to-Structured**: Use ML.GENERATE_TEXT for JSON extraction from documents\n",
    "2. **Chunking & Embedding**: In-datawarehouse RAG preparation with text-embedding models\n",
    "3. **Semantic Search**: ML.DISTANCE for efficient vector retrieval\n",
    "\n",
    "### Part 2: Cloud SQL Vector Store & Agentic RAG\n",
    "4. **pgvector Database**: High-performance operational vector store with Cloud SQL\n",
    "5. **RAG Agent**: Intelligent agent with function calling using ADK\n",
    "6. **Production Deployment**: Cloud Run deployment patterns\n",
    "\n",
    "**Architecture**: BigQuery (analytics) \u2192 Cloud SQL (serving) \u2192 Gemini Agent (intelligence)\n",
    "\n",
    "**Use Case**: Financial Services - Earnings call analysis, risk assessment, portfolio insights\n",
    "\n",
    "### Learning Goals\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "- Build a BigQuery-native RAG pipeline using ML.GENERATE_TEXT and ML.GENERATE_EMBEDDING\n",
    "- Set up Cloud SQL with pgvector as an operational vector store\n",
    "- Create a RAG agent using Google's Agent Development Kit (ADK)\n",
    "- Deploy your RAG agent to Cloud Run for production use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3103e9ed",
   "metadata": {
    "id": "3103e9ed"
   },
   "source": [
    "---\n",
    "\n",
    "## PART 1: BIGQUERY-NATIVE RAG PIPELINE\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08547c60",
   "metadata": {
    "id": "08547c60"
   },
   "source": [
    "## 0. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fe92a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44fe92a8",
    "outputId": "014fecba-ce0f-4ea3-93f9-ce676197eb93"
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform google-cloud-bigquery --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e701c4",
   "metadata": {
    "id": "d9e701c4"
   },
   "source": [
    "### \u26a0\ufe0f **Restart the Kernel**\n",
    "\n",
    "After installing the libraries, you must restart the kernel for the changes to take effect.\n",
    "\n",
    "**In Google Colab:** Go to **Runtime -> Restart session**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e92077c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e92077c",
    "outputId": "0d497313-3869-4aa4-dedb-6842341a5451"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Google Colab auth\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    print(\"Colab authentication successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ba6ec6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6ba6ec6",
    "outputId": "7998c076-11c2-4151-8f6a-bc4745e2e70a"
   },
   "outputs": [],
   "source": [
    "# --- \u26a0\ufe0f SET YOUR PROJECT DETAILS HERE ---\n",
    "PROJECT_ID = \"vertex-art-of-the-practical\"  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\"         # @param {type:\"string\"}\n",
    "BQ_DATASET = \"finserve_rag_db_v3\" # @param {type:\"string\"}\n",
    "BQ_CONNECTION = f\"projects/{PROJECT_ID}/locations/{REGION}/connections/bq_connection\"\n",
    "# --------------------------------------\n",
    "\n",
    "print(f\"Project: {PROJECT_ID}\")\n",
    "print(f\"Region: {REGION}\")\n",
    "print(f\"BigQuery Dataset: {BQ_DATASET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a3e6e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "488a3e6e",
    "outputId": "e4528e13-83cc-4389-a78b-a28cc6ece384"
   },
   "outputs": [],
   "source": [
    "# Enable necessary APIs\n",
    "!gcloud services enable aiplatform.googleapis.com --project {PROJECT_ID}\n",
    "!gcloud services enable bigquery.googleapis.com --project {PROJECT_ID}\n",
    "!gcloud services enable sqladmin.googleapis.com --project {PROJECT_ID}\n",
    "!gcloud services enable bigqueryconnection.googleapis.com --project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec637232",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ec637232",
    "outputId": "000441e7-ed6a-411d-95b9-60ecfabe4608"
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "from google.cloud import bigquery\n",
    "import json\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "# Initialize clients\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "print(\"Vertex AI and BigQuery clients initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06072241",
   "metadata": {
    "id": "06072241"
   },
   "source": [
    "## Step 1: Data & Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb336078",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cb336078",
    "outputId": "e62796f1-15af-4bb6-d76c-3e8ba3e000cc"
   },
   "outputs": [],
   "source": [
    "# Create the BigQuery dataset\n",
    "dataset = bigquery.Dataset(f\"{PROJECT_ID}.{BQ_DATASET}\")\n",
    "dataset.location = REGION\n",
    "try:\n",
    "    bq_client.create_dataset(dataset, timeout=30)\n",
    "    print(f\"Created BigQuery dataset: {BQ_DATASET}\")\n",
    "except Exception as e:\n",
    "    if \"Already Exists\" in str(e):\n",
    "        print(f\"BigQuery dataset {BQ_DATASET} already exists.\")\n",
    "    else:\n",
    "        print(f\"Error creating dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1764bdee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1764bdee",
    "outputId": "5d5b1588-014d-4285-c457-419a8604f702"
   },
   "outputs": [],
   "source": [
    "# Create BQ Connection\n",
    "print(\"Creating BQ Connection...\")\n",
    "!bq mk --connection \\\n",
    "    --connection_type=CLOUD_RESOURCE \\\n",
    "    --project_id={PROJECT_ID} \\\n",
    "    --location={REGION} \\\n",
    "    --quiet bq_connection\n",
    "\n",
    "try:\n",
    "    bq_command = [\n",
    "        \"bq\", \"show\",\n",
    "        \"--project_id\", PROJECT_ID,\n",
    "        \"--format=json\",\n",
    "        f\"--connection\", f\"{REGION}.bq_connection\"\n",
    "    ]\n",
    "    result = subprocess.run(bq_command, capture_output=True, text=True, check=True)\n",
    "    connection_details = json.loads(result.stdout)\n",
    "    SERVICE_ACCOUNT_ID = connection_details[\"cloudResource\"][\"serviceAccountId\"]\n",
    "\n",
    "    print(f\"Service Account ID: {SERVICE_ACCOUNT_ID}\")\n",
    "\n",
    "    !gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
    "        --member=\"serviceAccount:{SERVICE_ACCOUNT_ID}\" \\\n",
    "        --role=\"roles/aiplatform.user\"\n",
    "\n",
    "    print(f\"\u2705 Granted Vertex AI User role\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ef6f20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2ef6f20",
    "outputId": "155d0270-82c5-4469-de96-571245408c1a"
   },
   "outputs": [],
   "source": [
    "# Create and populate raw data\n",
    "sql_create_transcripts_table = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{PROJECT_ID}.{BQ_DATASET}.raw_earnings_call_transcripts` (\n",
    "  transcript_id STRING,\n",
    "  transcript_text STRING\n",
    ");\n",
    "\n",
    "INSERT INTO `{PROJECT_ID}.{BQ_DATASET}.raw_earnings_call_transcripts` (transcript_id, transcript_text)\n",
    "VALUES\n",
    "  ('txn_001', \"AlphaCorp (Ticker: APL) Q3 Earnings. CEO mentioned significant headwinds from supply chain disruption. Primary risk reported: 'semiconductor shortages'. Outlook: Cautious guidance for Q4, but optimistic on new product cycle.\"),\n",
    "  ('txn_002', \"BetaTech (Ticker: BTA) Q3. Strong growth in cloud division. CEO stated: 'Our AI services are seeing unprecedented adoption.' Risk: 'Intense market competition'. Outlook: Strong, raising full-year guidance.\"),\n",
    "  ('txn_003', \"GammaFin (Ticker: GFI) Q3. Missed on revenue. Primary risk: 'Interest rate volatility'. Outlook: Neutral. CEO mentioned 'cost-cutting measures' and 'focus on core assets'.\"),\n",
    "  ('txn_004', \"AlphaCorp (Ticker: APL) Q4 Update. Supply chain issues are easing. CEO: 'We are navigating the semiconductor shortage better than expected.' New risk: 'inflationary pressure on consumers'. Outlook: Stable.\");\n",
    "\"\"\"\n",
    "\n",
    "print(\"Creating raw data table...\")\n",
    "bq_client.query(sql_create_transcripts_table).result()\n",
    "print(\"\u2705 Raw data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f7c518",
   "metadata": {
    "id": "02f7c518"
   },
   "source": [
    "## Step 2: Unstructured-to-Structured (ML.GENERATE_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6660c23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6660c23",
    "outputId": "8ec52aa1-6cf5-42cb-ca92-a6c0aa3c7c9e"
   },
   "outputs": [],
   "source": [
    "# Create text generation model\n",
    "sql_create_llm_model = f\"\"\"\n",
    "CREATE OR REPLACE MODEL `{PROJECT_ID}.{BQ_DATASET}.gemini_flash_model`\n",
    "  REMOTE WITH CONNECTION `{BQ_CONNECTION}`\n",
    "  OPTIONS (endpoint = 'gemini-2.0-flash-exp');\n",
    "\"\"\"\n",
    "\n",
    "print(\"Creating BQML model...\")\n",
    "bq_client.query(sql_create_llm_model).result()\n",
    "print(\"\u2705 Model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae835ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ae835ea",
    "outputId": "4985ac31-deb4-4621-8200-aa6292672552"
   },
   "outputs": [],
   "source": [
    "# Extract structured JSON from text\n",
    "sql_transform = \"\"\"\n",
    "CREATE OR REPLACE TABLE `{PROJECT_ID}.{BQ_DATASET}.llm_raw_output` AS\n",
    "SELECT\n",
    "  transcript_id,\n",
    "  ml_generate_text_result AS raw_model_response\n",
    "FROM\n",
    "  ML.GENERATE_TEXT(\n",
    "    MODEL `{PROJECT_ID}.{BQ_DATASET}.gemini_flash_model`,\n",
    "    (\n",
    "      SELECT\n",
    "        transcript_id,\n",
    "        CONCAT(\n",
    "          '''\n",
    "          Extract structured data into valid JSON:\n",
    "          {{\n",
    "            \"company_ticker\": \"string\",\n",
    "            \"primary_risk\": \"string\",\n",
    "            \"ceo_outlook\": \"string\"\n",
    "          }}\n",
    "\n",
    "          Text:\n",
    "          ''',\n",
    "          transcript_text\n",
    "        ) AS prompt\n",
    "      FROM\n",
    "        `{PROJECT_ID}.{BQ_DATASET}.raw_earnings_call_transcripts`\n",
    "    ),\n",
    "    STRUCT(\n",
    "      0.2 AS temperature,\n",
    "      1024 AS max_output_tokens\n",
    "    )\n",
    "  );\n",
    "\"\"\".format(PROJECT_ID=PROJECT_ID, BQ_DATASET=BQ_DATASET)\n",
    "\n",
    "print(\"Extracting structured data...\")\n",
    "bq_client.query(sql_transform).result()\n",
    "print(\"\u2705 Extraction complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e04887",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "d0e04887",
    "outputId": "5bf16eee-40f8-4730-fec0-986df8c1bed3"
   },
   "outputs": [],
   "source": [
    "# Parse JSON and create final table\n",
    "sql_parse_and_clean = \"\"\"\n",
    "CREATE OR REPLACE TABLE `{PROJECT_ID}.{BQ_DATASET}.structured_earnings_summary` AS\n",
    "WITH\n",
    "  CleanedData AS (\n",
    "    SELECT\n",
    "      transcript_id,\n",
    "      SAFE.PARSE_JSON(\n",
    "        REGEXP_EXTRACT(\n",
    "          JSON_VALUE(raw_model_response, '$.candidates[0].content.parts[0].text'),\n",
    "          r'\\{{[\\s\\S]*\\}}'\n",
    "        )\n",
    "      ) AS report_data\n",
    "    FROM\n",
    "      `{PROJECT_ID}.{BQ_DATASET}.llm_raw_output`\n",
    "  )\n",
    "SELECT\n",
    "  transcript_id,\n",
    "  JSON_VALUE(report_data, '$.company_ticker') AS company_ticker,\n",
    "  JSON_VALUE(report_data, '$.primary_risk') AS primary_risk,\n",
    "  JSON_VALUE(report_data, '$.ceo_outlook') AS ceo_outlook\n",
    "FROM\n",
    "  CleanedData\n",
    "WHERE\n",
    "  report_data IS NOT NULL;\n",
    "\"\"\".format(PROJECT_ID=PROJECT_ID, BQ_DATASET=BQ_DATASET)\n",
    "\n",
    "bq_client.query(sql_parse_and_clean).result()\n",
    "print(\"\u2705 Structured table created\")\n",
    "\n",
    "# View results\n",
    "bq_client.query(f\"SELECT * FROM `{PROJECT_ID}.{BQ_DATASET}.structured_earnings_summary`\").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843c39fa",
   "metadata": {
    "id": "843c39fa"
   },
   "source": [
    "## Step 3: Build RAG Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f29cf87",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f29cf87",
    "outputId": "c65e1f87-452d-46a8-bc57-9c722458e346"
   },
   "outputs": [],
   "source": [
    "# Chunk documents by sentence\n",
    "sql_create_chunks = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{PROJECT_ID}.{BQ_DATASET}.earnings_call_chunks` AS\n",
    "WITH\n",
    "  NumberedTranscripts AS (\n",
    "    SELECT\n",
    "      ROW_NUMBER() OVER () AS doc_id,\n",
    "      transcript_id,\n",
    "      transcript_text\n",
    "    FROM\n",
    "      `{PROJECT_ID}.{BQ_DATASET}.raw_earnings_call_transcripts`\n",
    "  )\n",
    "SELECT\n",
    "  doc_id,\n",
    "  transcript_id,\n",
    "  CONCAT(CAST(doc_id AS STRING), '-', CAST(ROW_NUMBER() OVER (PARTITION BY doc_id) AS STRING)) as chunk_id,\n",
    "  TRIM(chunk) AS chunk_text\n",
    "FROM\n",
    "  NumberedTranscripts,\n",
    "  UNNEST(SPLIT(transcript_text, '.')) AS chunk\n",
    "WHERE\n",
    "  LENGTH(TRIM(chunk)) > 15;\n",
    "\"\"\"\n",
    "\n",
    "print(\"Chunking documents...\")\n",
    "bq_client.query(sql_create_chunks).result()\n",
    "print(\"\u2705 Chunking complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18455aa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "18455aa4",
    "outputId": "b73fa968-3c13-4e42-ba4e-ced3d8607c2e"
   },
   "outputs": [],
   "source": [
    "# Create embedding model\n",
    "sql_create_embedding_model = f\"\"\"\n",
    "CREATE OR REPLACE MODEL `{PROJECT_ID}.{BQ_DATASET}.embedding_model`\n",
    "  REMOTE WITH CONNECTION `{BQ_CONNECTION}`\n",
    "  OPTIONS (endpoint = 'text-embedding-005');\n",
    "\"\"\"\n",
    "\n",
    "print(\"Creating embedding model...\")\n",
    "bq_client.query(sql_create_embedding_model).result()\n",
    "print(\"\u2705 Model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f0591",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "420f0591",
    "outputId": "1db170da-8995-4880-a4d9-0c0dfea59d91"
   },
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "sql_embed_logs = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{PROJECT_ID}.{BQ_DATASET}.earnings_call_embeddings_chunked` AS\n",
    "SELECT\n",
    "  chunk_id,\n",
    "  chunk_text,\n",
    "  ml_generate_embedding_result AS embedding\n",
    "FROM\n",
    "  ML.GENERATE_EMBEDDING(\n",
    "    MODEL `{PROJECT_ID}.{BQ_DATASET}.embedding_model`,\n",
    "    (\n",
    "      SELECT\n",
    "        chunk_id,\n",
    "        chunk_text AS content,\n",
    "        chunk_text AS chunk_text\n",
    "      FROM\n",
    "        `{PROJECT_ID}.{BQ_DATASET}.earnings_call_chunks`\n",
    "    ),\n",
    "    STRUCT(TRUE AS flatten_json_output)\n",
    "  );\n",
    "\"\"\"\n",
    "\n",
    "print(\"Generating embeddings...\")\n",
    "bq_client.query(sql_embed_logs).result()\n",
    "print(\"\u2705 Embeddings created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26770eea",
   "metadata": {
    "id": "26770eea"
   },
   "source": [
    "## Step 4: RAG in Action (BigQuery-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3d7aa8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a3d7aa8",
    "outputId": "d0c273fc-1bdf-455a-9b54-4a1ef06a500e"
   },
   "outputs": [],
   "source": [
    "# Simple RAG query\n",
    "USER_QUERY = \"What are the main risks related to supply chain?\"\n",
    "\n",
    "sql_retrieve_context = f\"\"\"\n",
    "WITH UserQuery AS (\n",
    "  SELECT ml_generate_embedding_result AS query_embedding\n",
    "  FROM ML.GENERATE_EMBEDDING(\n",
    "    MODEL `{PROJECT_ID}.{BQ_DATASET}.embedding_model`,\n",
    "    (SELECT '{USER_QUERY}' AS content),\n",
    "    STRUCT(TRUE AS flatten_json_output)\n",
    "  )\n",
    ")\n",
    "SELECT\n",
    "  base.chunk_text,\n",
    "  ML.DISTANCE(\n",
    "    base.embedding,\n",
    "    query.query_embedding,\n",
    "    'COSINE'\n",
    "  ) AS distance\n",
    "FROM\n",
    "  `{PROJECT_ID}.{BQ_DATASET}.earnings_call_embeddings_chunked` AS base,\n",
    "  UserQuery AS query\n",
    "ORDER BY\n",
    "  distance ASC\n",
    "LIMIT 3\n",
    "\"\"\"\n",
    "\n",
    "context_df = bq_client.query(sql_retrieve_context).to_dataframe()\n",
    "print(\"--- Retrieved Context ---\")\n",
    "print(context_df)\n",
    "\n",
    "# Generate answer\n",
    "context_string = \"\\n---\\n\".join(context_df['chunk_text'])\n",
    "prompt = f\"\"\"\n",
    "Answer based only on this context:\n",
    "\n",
    "{context_string}\n",
    "\n",
    "Question: {USER_QUERY}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "model = GenerativeModel(\"gemini-2.0-flash-exp\")\n",
    "response = model.generate_content(prompt)\n",
    "print(\"\\n--- Answer ---\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab74972",
   "metadata": {
    "id": "cab74972"
   },
   "source": [
    "---\n",
    "\n",
    "## PART 2: CLOUD SQL VECTOR STORE & AGENTIC RAG\n",
    "\n",
    "Now we'll build a production-grade system with:\n",
    "- Cloud SQL + pgvector for low-latency queries\n",
    "- Intelligent RAG agent with function calling\n",
    "- Scalable deployment patterns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30270c2",
   "metadata": {
    "id": "f30270c2"
   },
   "source": [
    "## Step 5: Cloud SQL Vector Store Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d88f17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66d88f17",
    "outputId": "e225507f-bba9-47a1-e8fd-35b7a9129d85"
   },
   "outputs": [],
   "source": [
    "# === STEP 5a: PROVISION CLOUD SQL INSTANCE ===\n",
    "# This cell creates the Cloud SQL instance correctly from scratch.\n",
    "# It takes 15-20 minutes. Please be patient!\n",
    "\n",
    "INSTANCE_NAME = \"finserve-knowledge-engine-2\" # You can change this name if it conflicts\n",
    "DB_NAME = \"financial_knowledge\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"FinServe2024!\" # CHANGE IN PRODUCTION\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "print(f\"--- INFRASTRUCTURE SETUP ---\")\n",
    "print(f\"Instance: {INSTANCE_NAME}\")\n",
    "print(f\"Region: {REGION}\")\n",
    "\n",
    "# 1. Delete old instance if it exists (optional, uncomment if needed to retry)\n",
    "# print(f\"Deleting old instance '{INSTANCE_NAME}' (if it exists)...\")\n",
    "# !gcloud sql instances delete {INSTANCE_NAME} --project={PROJECT_ID} --quiet\n",
    "\n",
    "# 2. Create the instance with the CRITICAL flag for Vertex AI integration\n",
    "print(f\"\\nCreating Cloud SQL instance (this takes 15-20 mins)...\")\n",
    "!gcloud sql instances create {INSTANCE_NAME} \\\n",
    "    --database-version=POSTGRES_15 \\\n",
    "    --cpu=1 \\\n",
    "    --memory=4GiB \\\n",
    "    --region={REGION} \\\n",
    "    --project={PROJECT_ID} \\\n",
    "    --enable-google-ml-integration \\\n",
    "    --quiet\n",
    "\n",
    "print(f\"Instance created. Creating database '{DB_NAME}'...\")\n",
    "!gcloud sql databases create {DB_NAME} --instance={INSTANCE_NAME} --project={PROJECT_ID} --quiet\n",
    "\n",
    "print(f\"Database created. Setting password for user '{DB_USER}'...\")\n",
    "!gcloud sql users set-password {DB_USER} --instance={INSTANCE_NAME} --password={DB_PASSWORD} --project={PROJECT_ID} --quiet\n",
    "\n",
    "print(\"\\n\u2705 Cloud SQL infrastructure successfully provisioned with ML integration!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ad4b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd2ad4b4",
    "outputId": "969ac6c3-19cd-4f2f-8ff6-fba1534817f3"
   },
   "outputs": [],
   "source": [
    "# Install Cloud SQL connector\n",
    "!pip install cloud-sql-python-connector[pg8000] sqlalchemy --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# === FIX: Enable Outbound Connectivity for Vertex AI ===\n",
    "# The 'google_ml_integration' extension needs to make outbound calls to Vertex AI.\n",
    "# We must enable this explicitly on the Cloud SQL instance.\n",
    "\n",
    "print(f\"Enabling outbound public IP for instance '{INSTANCE_NAME}'...\")\n",
    "\n",
    "!gcloud sql instances patch {INSTANCE_NAME} \\\n",
    "    --project={PROJECT_ID} \\\n",
    "    --assign-ip \\\n",
    "    --quiet\n",
    "\n",
    "print(\"\u2705 Outbound connectivity enabled. Waiting 2 minutes for changes to propagate...\")\n",
    "import time\n",
    "time.sleep(120) # Give it time to restart/update internally\n",
    "print(\"Ready to connect.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L20E23PMY2HD",
    "outputId": "94cddb6d-bd41-437a-e6b2-f381cd3c78ae"
   },
   "id": "L20E23PMY2HD",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "roles/cloudsql.client"
   ],
   "metadata": {
    "id": "FCmCwQ21VNnX"
   },
   "id": "FCmCwQ21VNnX"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5fdbf7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca5fdbf7",
    "outputId": "e1789254-4537-4bc3-dab0-e068889c47c1"
   },
   "outputs": [],
   "source": [
    "from google.cloud.sql.connector import Connector\n",
    "import sqlalchemy\n",
    "import pg8000\n",
    "\n",
    "connector = Connector()\n",
    "\n",
    "def get_db_connection():\n",
    "    conn = connector.connect(\n",
    "        f\"{PROJECT_ID}:{REGION}:{INSTANCE_NAME}\",\n",
    "        \"pg8000\",\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD,\n",
    "        db=DB_NAME\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "engine = sqlalchemy.create_engine(\n",
    "    \"postgresql+pg8000://\",\n",
    "    creator=get_db_connection,\n",
    ")\n",
    "\n",
    "print(\"\u2705 Cloud SQL connection established\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0007dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff0007dd",
    "outputId": "f57a213d-ea14-4c14-9661-4379ca34395c"
   },
   "outputs": [],
   "source": [
    "# Enable extensions\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(sqlalchemy.text(\"CREATE EXTENSION IF NOT EXISTS vector;\"))\n",
    "    conn.execute(sqlalchemy.text(\"CREATE EXTENSION IF NOT EXISTS google_ml_integration CASCADE;\"))\n",
    "    conn.commit()\n",
    "    print(\"\u2705 pgvector enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf03af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cfcf03af",
    "outputId": "d4036647-a8e9-4428-a67a-3bee7df6c1d4"
   },
   "outputs": [],
   "source": [
    "# Create knowledge table\n",
    "create_table_sql = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS earnings_knowledge (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    chunk_id TEXT,\n",
    "    company_ticker TEXT,\n",
    "    document_type TEXT,\n",
    "    chunk_content TEXT,\n",
    "    embedding VECTOR(768)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(sqlalchemy.text(create_table_sql))\n",
    "    conn.commit()\n",
    "    print(\"\u2705 Table created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ce435f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73ce435f",
    "outputId": "713d0df9-a11a-420f-8a6f-4b6101c497d4"
   },
   "outputs": [],
   "source": [
    "# Load data from BigQuery\n",
    "bq_data_query = f\"\"\"\n",
    "SELECT\n",
    "    chunk_id,\n",
    "    chunk_text,\n",
    "    embedding\n",
    "FROM `{PROJECT_ID}.{BQ_DATASET}.earnings_call_embeddings_chunked`\n",
    "\"\"\"\n",
    "\n",
    "df_embeddings = bq_client.query(bq_data_query).to_dataframe()\n",
    "print(f\"Fetched {len(df_embeddings)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# === GRANT PERMISSIONS TO CLOUD SQL SERVICE ACCOUNT ===\n",
    "# The Cloud SQL instance has its own service account. IT needs permission to call Vertex AI.\n",
    "\n",
    "print(f\"Fetching service account for Cloud SQL instance '{INSTANCE_NAME}'...\")\n",
    "sql_sa = !gcloud sql instances describe {INSTANCE_NAME} --project={PROJECT_ID} --format=\"value(serviceAccountEmailAddress)\"\n",
    "SQL_SERVICE_ACCOUNT = sql_sa[0]\n",
    "print(f\"Cloud SQL Service Account: {SQL_SERVICE_ACCOUNT}\")\n",
    "\n",
    "print(\"Granting 'Vertex AI User' role to Cloud SQL Service Account...\")\n",
    "!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
    "    --member=\"serviceAccount:{SQL_SERVICE_ACCOUNT}\" \\\n",
    "    --role=\"roles/aiplatform.user\" \\\n",
    "    --quiet\n",
    "\n",
    "print(\"Granting 'Vertex AI Service Agent' role (belt and suspenders)...\")\n",
    "!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
    "    --member=\"serviceAccount:{SQL_SERVICE_ACCOUNT}\" \\\n",
    "    --role=\"roles/aiplatform.serviceAgent\" \\\n",
    "    --quiet\n",
    "\n",
    "print(\"\\n\u2705 Permissions granted. Waiting 60 seconds for propagation...\")\n",
    "import time\n",
    "time.sleep(60)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6dpd3lgLiA7Y",
    "outputId": "c4177810-98e4-4bf8-e4e6-46ca5fd07e8a"
   },
   "id": "6dpd3lgLiA7Y",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c60039",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72c60039",
    "outputId": "1c82d595-dcaf-4a9e-e3c5-b74f1ea9100a"
   },
   "outputs": [],
   "source": [
    "# Insert with Cloud SQL embedding function\n",
    "insert_count = 0\n",
    "with engine.connect() as conn:\n",
    "    for _, row in df_embeddings.iterrows():\n",
    "        ticker = \"UNKNOWN\"\n",
    "        if \"Alpha\" in row['chunk_text']:\n",
    "            ticker = \"APL\"\n",
    "        elif \"Beta\" in row['chunk_text']:\n",
    "            ticker = \"BTA\"\n",
    "        elif \"Gamma\" in row['chunk_text']:\n",
    "            ticker = \"GFI\"\n",
    "\n",
    "        insert_sql = sqlalchemy.text(\"\"\"\n",
    "            INSERT INTO earnings_knowledge (chunk_id, company_ticker, document_type, chunk_content, embedding)\n",
    "            VALUES (:chunk_id, :ticker, 'EARNINGS_CALL', :content,\n",
    "                    (embedding('text-embedding-005', :content))::vector)\n",
    "        \"\"\")\n",
    "\n",
    "        conn.execute(insert_sql, {\n",
    "            'chunk_id': row['chunk_id'],\n",
    "            'ticker': ticker,\n",
    "            'content': row['chunk_text']\n",
    "        })\n",
    "        insert_count += 1\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "print(f\"\u2705 Inserted {insert_count} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bd80f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82bd80f9",
    "outputId": "e4b1beb6-3103-436f-b529-239e062052e4"
   },
   "outputs": [],
   "source": [
    "# Create HNSW index\n",
    "create_index_sql = \"\"\"\n",
    "CREATE INDEX IF NOT EXISTS earnings_knowledge_embedding_idx\n",
    "ON earnings_knowledge\n",
    "USING hnsw (embedding vector_cosine_ops);\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(sqlalchemy.text(create_index_sql))\n",
    "    conn.commit()\n",
    "    print(\"\u2705 HNSW index created for fast search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184da67a",
   "metadata": {
    "id": "184da67a"
   },
   "source": [
    "## Step 6: Build RAG Agent with ADK (Agent Development Kit)\n",
    "\n",
    "We'll use Google's Agent Development Kit to create a production-ready RAG agent with proper tool use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c551cc1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c551cc1",
    "outputId": "5c87ad1d-ff56-44bb-adb3-5e83b4948a6e"
   },
   "outputs": [],
   "source": [
    "# Install ADK\n",
    "!pip install google-genai --upgrade --quiet\n",
    "!pip install google-adk --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad5bfe6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ad5bfe6",
    "outputId": "31063d61-a4ac-45f2-bb6c-7063aa568fcd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GOOGLE_GENAI_USE_VERTEXAI'] = 'TRUE'\n",
    "os.environ['GOOGLE_CLOUD_PROJECT'] = PROJECT_ID\n",
    "os.environ['GOOGLE_CLOUD_LOCATION'] = REGION\n",
    "\n",
    "from google import genai\n",
    "from google.genai.types import EmbedContentConfig\n",
    "\n",
    "# Initialize Genai client for embeddings\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=REGION)\n",
    "\n",
    "def knowledge_lookup(company_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the financial knowledge base for information about companies.\n",
    "\n",
    "    Args:\n",
    "        company_query: The company name, ticker, or financial topic to search for\n",
    "\n",
    "    Returns:\n",
    "        Relevant information from earnings calls and financial documents\n",
    "    \"\"\"\n",
    "    print(f\"\\n\ud83d\udd0d TOOL CALLED: knowledge_lookup('{company_query}')\")\n",
    "\n",
    "    # Step 1: Convert query to embedding using Gemini\n",
    "    result = client.models.embed_content(\n",
    "        model=\"text-embedding-005\",\n",
    "        contents=company_query,\n",
    "        config=EmbedContentConfig(\n",
    "            task_type=\"RETRIEVAL_DOCUMENT\",\n",
    "            output_dimensionality=768,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    query_embedding = result.embeddings[0].values\n",
    "\n",
    "    # Step 2: Perform cosine similarity search in pgvector\n",
    "    search_sql = \"\"\"\n",
    "        SELECT\n",
    "            company_ticker,\n",
    "            chunk_content\n",
    "        FROM earnings_knowledge\n",
    "        ORDER BY embedding <=> %s\n",
    "        LIMIT 3\n",
    "    \"\"\"\n",
    "\n",
    "    with engine.connect() as conn:\n",
    "        with conn.connection.cursor() as cursor:\n",
    "            cursor.execute(search_sql, ([query_embedding],))\n",
    "            results = cursor.fetchall()\n",
    "\n",
    "    # Step 3: Format results for the agent\n",
    "    if not results:\n",
    "        return \"No relevant information found in the knowledge base.\"\n",
    "\n",
    "    formatted_output = \"\\n\\n\".join([\n",
    "        f\"[{row[0]}] {row[1]}\" for row in results\n",
    "    ])\n",
    "\n",
    "    print(f\"\u2705 Retrieved {len(results)} relevant chunks\\n\")\n",
    "    return formatted_output\n",
    "\n",
    "print(\"\u2705 knowledge_lookup tool defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57bb4e",
   "metadata": {
    "id": "7e57bb4e"
   },
   "source": [
    "### Step 6b: Create the ADK Agent\n",
    "\n",
    "Using ADK's LlmAgent with the knowledge_lookup tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083b86b0",
   "metadata": {
    "id": "083b86b0"
   },
   "source": [
    "### Step 6a: Create the Knowledge Lookup Tool\n",
    "\n",
    "This tool will query our pgvector database using semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389edc8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a389edc8",
    "outputId": "4c2f3edb-873c-4985-ad2c-5e5ebf4bdf2c"
   },
   "outputs": [],
   "source": [
    "from google.adk.agents import LlmAgent\n",
    "\n",
    "# Create the Financial Analyst RAG Agent using ADK\n",
    "financial_analyst_agent = LlmAgent(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    name=\"financial_analyst\",\n",
    "    description=\"A financial analyst that answers questions about companies, risks, and earnings using a knowledge base\",\n",
    "    instruction=\"\"\"\n",
    "        You are a Senior Financial Analyst with expertise in earnings analysis and risk assessment.\n",
    "\n",
    "        **Your Process:**\n",
    "        1. When asked about companies, risks, or financial topics, ALWAYS use the `knowledge_lookup` tool first\n",
    "        2. Base your analysis ONLY on the information retrieved from the knowledge base\n",
    "        3. If the knowledge base doesn't have relevant information, clearly state that\n",
    "        4. Provide concise, actionable insights with specific citations (company ticker)\n",
    "        5. Structure your responses professionally with clear bullet points when appropriate\n",
    "\n",
    "        **Analysis Guidelines:**\n",
    "        - Highlight key risks and opportunities\n",
    "        - Compare across companies when relevant\n",
    "        - Focus on material information (supply chain, market conditions, CEO guidance)\n",
    "        - Use financial terminology appropriately\n",
    "\n",
    "        **Output Format:**\n",
    "        Provide clear, evidence-based analysis citing the specific company sources.\n",
    "    \"\"\",\n",
    "    tools=[knowledge_lookup],\n",
    ")\n",
    "\n",
    "print(\"\u2705 Financial Analyst Agent initialized with ADK\")\n",
    "print(f\"   Model: gemini-2.5-flash\")\n",
    "print(f\"   Tools: [knowledge_lookup]\")\n",
    "print(f\"   Status: Ready for queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9236112",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9236112",
    "outputId": "3089373f-9834-426b-c47e-6941b949a6fe"
   },
   "outputs": [],
   "source": [
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService, Session\n",
    "from google.genai import types\n",
    "import uuid\n",
    "\n",
    "# Setup ADK session and runner\n",
    "APP_NAME = \"financial_rag_app\"\n",
    "USER_ID = \"analyst_user\"\n",
    "\n",
    "# Create session service\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "# Create runner with the agent\n",
    "runner = Runner(\n",
    "    agent=financial_analyst_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service\n",
    ")\n",
    "\n",
    "# Create a persistent session ID for this conversation\n",
    "session_id = str(uuid.uuid4())\n",
    "\n",
    "def query_agent(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Send a query to the financial analyst agent using ADK Runner.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"USER QUESTION: {question}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "    try:\n",
    "        # Ensure session exists before each query\n",
    "        try:\n",
    "            session_service.get_session(\n",
    "                app_name=APP_NAME,\n",
    "                user_id=USER_ID,\n",
    "                session_id=session_id\n",
    "            )\n",
    "        except:\n",
    "            # Create session if it doesn't exist\n",
    "            session_service.create_session(\n",
    "                app_name=APP_NAME,\n",
    "                user_id=USER_ID,\n",
    "                session_id=session_id\n",
    "            )\n",
    "\n",
    "        # Create user message content\n",
    "        content = types.Content(\n",
    "            role='user',\n",
    "            parts=[types.Part(text=question)]\n",
    "        )\n",
    "\n",
    "        # Run the agent with proper session management\n",
    "        events = runner.run(\n",
    "            user_id=USER_ID,\n",
    "            session_id=session_id,\n",
    "            new_message=content\n",
    "        )\n",
    "\n",
    "        # Process events and extract final response\n",
    "        response_text = \"\"\n",
    "        for event in events:\n",
    "            # Debug: show tool calls\n",
    "            if hasattr(event, 'tool_call') and event.tool_call:\n",
    "                print(f\"\ud83d\udd27 Tool called: {event.tool_call.name}\")\n",
    "\n",
    "            # Extract final response\n",
    "            if event.is_final_response() and event.content:\n",
    "                for part in event.content.parts:\n",
    "                    if hasattr(part, 'text') and part.text:\n",
    "                        response_text = part.text.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        response_text = f\"ERROR: Could not interact with agent.\\n{str(e)}\\n\\nTraceback:\\n{traceback.format_exc()}\"\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"AGENT RESPONSE:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(response_text)\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "    return response_text\n",
    "\n",
    "print(\"\u2705 Helper function ready (using ADK Runner)\")\n",
    "print(f\"   App: {APP_NAME}\")\n",
    "print(f\"   User: {USER_ID}\")\n",
    "print(f\"   Session ID: {session_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510ea404",
   "metadata": {
    "id": "510ea404"
   },
   "source": [
    "### Step 6c: Helper Function for Agent Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61907f7e",
   "metadata": {
    "id": "61907f7e"
   },
   "source": [
    "### Test the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b86f69d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "id": "2b86f69d",
    "outputId": "c8da4e64-d79f-4ad8-efd4-c4553231e96f"
   },
   "outputs": [],
   "source": [
    "# Test 1: Supply chain risks\n",
    "query_agent(\"What are the main supply chain challenges?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a73aef6",
   "metadata": {
    "id": "4a73aef6"
   },
   "outputs": [],
   "source": [
    "# Test 2: Company outlook\n",
    "query_agent(\"What is BetaTech's outlook?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce58bf85",
   "metadata": {
    "id": "ce58bf85"
   },
   "outputs": [],
   "source": [
    "# Test 3: Risk comparison\n",
    "query_agent(\"Compare risks across all companies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba12f6a3",
   "metadata": {
    "id": "ba12f6a3"
   },
   "outputs": [],
   "source": [
    "# Create agent.py for deployment\n",
    "agent_code = \"\"\"\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai.adk import LlmAgent\n",
    "from google.genai.types import EmbedContentConfig\n",
    "from cloud_sql_python_connector import Connector\n",
    "import sqlalchemy\n",
    "import pg8000\n",
    "\n",
    "# Environment variables\n",
    "PROJECT_ID = os.getenv('GOOGLE_CLOUD_PROJECT')\n",
    "REGION = os.getenv('GOOGLE_CLOUD_LOCATION', 'us-central1')\n",
    "INSTANCE_NAME = os.getenv('CLOUD_SQL_INSTANCE')\n",
    "DB_USER = os.getenv('DB_USER', 'postgres')\n",
    "DB_PASSWORD = os.getenv('DB_PASSWORD')\n",
    "DB_NAME = os.getenv('DB_NAME', 'financial_knowledge')\n",
    "\n",
    "os.environ['GOOGLE_GENAI_USE_VERTEXAI'] = 'TRUE'\n",
    "\n",
    "# Initialize connections\n",
    "connector = Connector()\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=REGION)\n",
    "\n",
    "def get_db_connection():\n",
    "    conn = connector.connect(\n",
    "        INSTANCE_NAME,\n",
    "        \"pg8000\",\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD,\n",
    "        db=DB_NAME\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "engine = sqlalchemy.create_engine(\n",
    "    \"postgresql+pg8000://\",\n",
    "    creator=get_db_connection,\n",
    ")\n",
    "\n",
    "def knowledge_lookup(company_query: str) -> str:\n",
    "    result = client.models.embed_content(\n",
    "        model=\"text-embedding-005\",\n",
    "        contents=company_query,\n",
    "        config=EmbedContentConfig(\n",
    "            task_type=\"RETRIEVAL_DOCUMENT\",\n",
    "            output_dimensionality=768,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    query_embedding = result.embeddings[0].values\n",
    "\n",
    "    search_sql = \"SELECT company_ticker, chunk_content FROM earnings_knowledge ORDER BY embedding <=> %s LIMIT 3\"\n",
    "\n",
    "    with engine.connect() as conn:\n",
    "        with conn.connection.cursor() as cursor:\n",
    "            cursor.execute(search_sql, ([query_embedding],))\n",
    "            results = cursor.fetchall()\n",
    "\n",
    "    if not results:\n",
    "        return \"No relevant information found.\"\n",
    "\n",
    "    return \"\\\\n\\\\n\".join([f\"[{row[0]}] {row[1]}\" for row in results])\n",
    "\n",
    "# Create the agent\n",
    "financial_analyst = LlmAgent(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    name=\"financial_analyst\",\n",
    "    instruction='''\n",
    "        You are a Senior Financial Analyst. Use knowledge_lookup to answer questions\n",
    "        about companies, risks, and earnings. Base answers ONLY on retrieved data.\n",
    "    ''',\n",
    "    tools=[knowledge_lookup],\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "with open('agent.py', 'w') as f:\n",
    "    f.write(agent_code)\n",
    "\n",
    "print(\"\u2705 agent.py created\")\n",
    "print(\"\\\\nTo run locally:\")\n",
    "print(\"  adk run financial_analyst\")\n",
    "print(\"\\\\nAgent will be available at: http://localhost:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed1e647",
   "metadata": {
    "id": "eed1e647"
   },
   "outputs": [],
   "source": [
    "# Dataflow pipeline for continuous embedding\n",
    "dataflow_pipeline = \"\"\"\n",
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from google.cloud import aiplatform\n",
    "import sqlalchemy\n",
    "from cloud_sql_python_connector import Connector\n",
    "\n",
    "class EmbedAndStore(beam.DoFn):\n",
    "    def __init__(self, project, region, instance):\n",
    "        self.project = project\n",
    "        self.region = region\n",
    "        self.instance = instance\n",
    "\n",
    "    def setup(self):\n",
    "        aiplatform.init(project=self.project, location=self.region)\n",
    "        connector = Connector()\n",
    "\n",
    "        def get_conn():\n",
    "            return connector.connect(\n",
    "                self.instance,\n",
    "                \"pg8000\",\n",
    "                user=\"postgres\",\n",
    "                password=os.getenv(\"DB_PASSWORD\"),\n",
    "                db=\"financial_knowledge\"\n",
    "            )\n",
    "\n",
    "        self.engine = sqlalchemy.create_engine(\n",
    "            \"postgresql+pg8000://\",\n",
    "            creator=get_conn\n",
    "        )\n",
    "\n",
    "    def process(self, element):\n",
    "        # Generate embedding\n",
    "        from vertexai.language_models import TextEmbeddingModel\n",
    "        model = TextEmbeddingModel.from_pretrained(\"text-embedding-005\")\n",
    "        embedding = model.get_embeddings([element['text']])[0].values\n",
    "\n",
    "        # Insert to Cloud SQL\n",
    "        with self.engine.connect() as conn:\n",
    "            conn.execute(\n",
    "                sqlalchemy.text(\n",
    "                    \"INSERT INTO earnings_knowledge (chunk_id, company_ticker, chunk_content, embedding) \"\n",
    "                    \"VALUES (:id, :ticker, :content, :embed)\"\n",
    "                ),\n",
    "                {\n",
    "                    'id': element['id'],\n",
    "                    'ticker': element['ticker'],\n",
    "                    'content': element['text'],\n",
    "                    'embed': embedding\n",
    "                }\n",
    "            )\n",
    "\n",
    "        yield element\n",
    "\n",
    "def run_pipeline():\n",
    "    options = PipelineOptions(\n",
    "        runner='DataflowRunner',\n",
    "        project='YOUR_PROJECT_ID',\n",
    "        region='us-central1',\n",
    "        temp_location='gs://YOUR_BUCKET/temp'\n",
    "    )\n",
    "\n",
    "    with beam.Pipeline(options=options) as p:\n",
    "        (p\n",
    "         | 'Read from BigQuery' >> beam.io.ReadFromBigQuery(\n",
    "             query='SELECT chunk_id, chunk_text, company FROM earnings_raw WHERE processed = FALSE'\n",
    "         )\n",
    "         | 'Embed and Store' >> beam.ParDo(EmbedAndStore(\n",
    "             project='YOUR_PROJECT_ID',\n",
    "             region='us-central1',\n",
    "             instance='YOUR_INSTANCE'\n",
    "         ))\n",
    "        )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_pipeline()\n",
    "\"\"\"\n",
    "\n",
    "with open('vectorization_pipeline.py', 'w') as f:\n",
    "    f.write(dataflow_pipeline)\n",
    "\n",
    "print(\"\u2705 Dataflow pipeline created\")\n",
    "print(\"\\\\nTo run:\")\n",
    "print(\"  python vectorization_pipeline.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92368c41",
   "metadata": {
    "id": "92368c41"
   },
   "source": [
    "### Optional: Continuous Vectorization Pipeline with Dataflow\n",
    "\n",
    "Keep the knowledge base updated as new earnings calls are added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b792e974",
   "metadata": {
    "id": "b792e974"
   },
   "outputs": [],
   "source": [
    "# Deploy to Cloud Run\ndeploy_script = f\"\"\"\n#!/bin/bash\nset -e\n\n# Variables\nSERVICE_NAME=\"financial-analyst-agent\"\nREGION=\"{REGION}\"\nPROJECT_ID=\"{PROJECT_ID}\"\nCLOUD_SQL_INSTANCE=\"{CLOUD_SQL_INSTANCE_NAME}\"\n\necho \"Building container...\"\ngcloud builds submit --tag gcr.io/$$PROJECT_ID/$$SERVICE_NAME\n\necho \"Deploying to Cloud Run...\"\ngcloud run deploy $$SERVICE_NAME \\\\\n  --image gcr.io/$$PROJECT_ID/$$SERVICE_NAME \\\\\n  --platform managed \\\\\n  --region $$REGION \\\\\n  --allow-unauthenticated \\\\\n  --set-env-vars GOOGLE_GENAI_USE_VERTEXAI=TRUE \\\\\n  --set-env-vars GOOGLE_CLOUD_PROJECT=$$PROJECT_ID \\\\\n  --set-env-vars GOOGLE_CLOUD_LOCATION=$$REGION \\\\\n  --set-env-vars CLOUD_SQL_INSTANCE=$$CLOUD_SQL_INSTANCE \\\\\n  --set-env-vars DB_USER={DB_USER} \\\\\n  --set-env-vars DB_NAME={DB_NAME} \\\\\n  --set-env-vars A2A_HOST=0.0.0.0 \\\\\n  --set-env-vars A2A_PORT=8080 \\\\\n  --set-secrets DB_PASSWORD=db-password:latest \\\\\n  --add-cloudsql-instances $$CLOUD_SQL_INSTANCE \\\\\n  --memory 2Gi \\\\\n  --timeout 300 \\\\\n  --max-instances 10\n\necho \"Deployment complete!\"\ngcloud run services describe $$SERVICE_NAME --region $$REGION --format 'value(status.url)'\n\"\"\"\n\nwith open('deploy.sh', 'w') as f:\n    f.write(deploy_script)\n\nprint(\"\u2705 deploy.sh created\")\nprint(\"\\\\nTo deploy:\")\nprint(\"  chmod +x deploy.sh\")\nprint(\"  ./deploy.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d6643",
   "metadata": {
    "id": "0e2d6643"
   },
   "outputs": [],
   "source": [
    "# Create Dockerfile for ADK agent\n",
    "dockerfile_content = \"\"\"\n",
    "FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Install dependencies\n",
    "RUN pip install --no-cache-dir \\\\\n",
    "    google-genai-sdk \\\\\n",
    "    cloud-sql-python-connector[pg8000] \\\\\n",
    "    sqlalchemy\n",
    "\n",
    "# Copy agent code\n",
    "COPY agent.py .\n",
    "\n",
    "# ADK environment variables\n",
    "ENV A2A_HOST=0.0.0.0\n",
    "ENV A2A_PORT=8080\n",
    "\n",
    "# Run the agent\n",
    "CMD [\"python\", \"-m\", \"google.genai.adk.cli\", \"run\", \"financial_analyst\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
    "\"\"\"\n",
    "\n",
    "with open('Dockerfile', 'w') as f:\n",
    "    f.write(dockerfile_content)\n",
    "\n",
    "print(\"\u2705 Dockerfile created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2263f78b",
   "metadata": {
    "id": "2263f78b"
   },
   "source": [
    "## Step 7: Production Deployment to Cloud Run\n",
    "\n",
    "Deploy the ADK agent to Cloud Run for scalable, serverless hosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932b27c",
   "metadata": {
    "id": "e932b27c"
   },
   "source": [
    "### Alternative: Run with ADK CLI\n",
    "\n",
    "For production deployment, you can create an `agent.py` file and run with `adk run`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfeed19",
   "metadata": {
    "id": "bcfeed19"
   },
   "source": [
    "## Summary\n",
    "\n",
    "You've built a complete enterprise RAG knowledge engine with:\n",
    "\n",
    "### \u2705 Data Pipeline\n",
    "- BigQuery for analytics and batch processing\n",
    "- ML.GENERATE_TEXT for structured extraction\n",
    "- Chunking & embedding at scale\n",
    "\n",
    "### \u2705 Vector Store\n",
    "- Cloud SQL + pgvector for low-latency queries\n",
    "- HNSW indexing for sub-second search\n",
    "- Hybrid storage (metadata + vectors)\n",
    "\n",
    "### \u2705 Intelligent Agent\n",
    "- Function calling for tool use\n",
    "- RAG pattern (Retrieve \u2192 Augment \u2192 Generate)\n",
    "- Grounded, cited responses\n",
    "\n",
    "### \ud83d\ude80 Production Ready\n",
    "- Deploy to Cloud Run\n",
    "- Dataflow for continuous ingestion\n",
    "- Scalable to millions of documents"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
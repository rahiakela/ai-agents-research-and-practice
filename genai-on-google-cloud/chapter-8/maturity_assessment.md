# AI and Agentic Maturity Self-Assessment Workbook

This workbook helps organizations assess their current AI maturity across three dimensions: Vision & Leadership, Talent & Culture, and Operational & Technical Practice.

## How to Use This Assessment

### Preparation

1. **Gather Stakeholders**: Include representatives from:
   - Executive leadership (CEO, CIO, CTO)
   - HR and talent management
   - Technical teams (data science, engineering, MLOps)
   - Business unit leaders
   - Legal/compliance

2. **Assessment Approach**:
   - Have each stakeholder complete the assessment independently
   - Compare and discuss areas of significant disagreement
   - Use the [maturity_rubric.md](./maturity_rubric.md) for detailed phase descriptions

3. **Scoring Guide**:
   | Score | Phase | Description |
   |-------|-------|-------------|
   | 1 | Tactical (Early) | No evidence or just beginning |
   | 2 | Tactical (Late) | Some evidence but not systematic |
   | 3 | Strategic (Early) | Systematic approach in place |
   | 4 | Strategic (Mature) | Well-established and measured |
   | 5 | Transformational | Industry-leading, self-optimizing |

---

## Section 1: Vision & Leadership

*The "What" and "Why" dimension - assessing strategic alignment and executive commitment.*

### Questions

Rate each question from 1 (Tactical) to 5 (Transformational):

| # | Question | Score (1-5) | Notes |
|---|----------|-------------|-------|
| V1 | What are the top three business KPIs our AI systems are expected to impact this quarter, and how will we measure that impact? | ___ | |
| V2 | What is our error budget for AI initiatives? Who declares a project successful enough to scale? | ___ | |
| V3 | Who centralizes governance for similar AI solutions to prevent waste and ensure reusability? | ___ | |
| V4 | Is AI funding from a dedicated, multiyear budget, or annual, fluctuating funds? | ___ | |
| V5 | Is our hiring plan aligned with the AI roadmap? | ___ | |
| V6 | How does our AI strategy provide a measurable competitive advantage in the next 24 months? | ___ | |
| V7 | How many personas/job roles actively use AI/agentic tools? | ___ | |
| V8 | What is the plan to make AI the default operating method for all employees? | ___ | |
| V9 | Can our CEO articulate AI's role in our company's future market identity? | ___ | |
| V10 | What proactive steps are we taking to meet global AI compliance standards (e.g., EU AI Act)? | ___ | |
| V11 | What measurable mechanism ensures our Responsible AI principles are enforced and audited across all new enterprise AI products before deployment? | ___ | |
| V12 | Is there a documented short-, mid-, and long-term vision and roadmap for AI and agents? | ___ | |

### Vision & Leadership Score

| Metric | Value |
|--------|-------|
| **Total Score** | ___/60 |
| **Average Score** | ___/5 |
| **Phase** | Tactical / Strategic / Transformational |

---

## Section 2: Talent & Culture

*The "Who" dimension - assessing workforce readiness and cultural openness.*

### Questions

| # | Question | Score (1-5) | Notes |
|---|----------|-------------|-------|
| T1 | How will we mandate and fund structured collaboration between AI specialists and business unit SMEs to ensure viable and relevant solutions? | ___ | |
| T2 | If AI automates 30% of a non-technical role, what incentivized upskilling pathway is available to that employee for higher-value, AI-augmented tasks? Is this training universally accessible? | ___ | |
| T3 | What is the explicit governance for reviewing failed AI experiments? Will they be treated as learning investments or budget losses, and who communicates this? | ___ | |
| T4 | When hiring VPs or HR leads, is AI fluency a core, non-negotiable competency? If not, what is the timeline for making AI expertise a basic qualification across all leadership? | ___ | |
| T5 | Instead of hiring for current AI needs, what is our strategy for cultivating skills for emerging agentic paradigms anticipated in 18 months? | ___ | |
| T6 | Is there a dedicated R&D budget for upskilling? | ___ | |
| T7 | How do we define our unique human-AI collaboration model? | ___ | |
| T8 | Can every employee articulate how AI augments their job, and how do we measure the cultural impact (e.g., job satisfaction, innovation output) beyond technical metrics? | ___ | |

### Talent & Culture Score

| Metric | Value |
|--------|-------|
| **Total Score** | ___/40 |
| **Average Score** | ___/5 |
| **Phase** | Tactical / Strategic / Transformational |

---

## Section 3: Operational & Technical Practice

*The "How" dimension - assessing execution capabilities across six subdomains.*

### Questions

| # | Question | Score (1-5) | Notes |
|---|----------|-------------|-------|
| O1 | Would a mid-level engineer be able to replicate a top AI engineer's production environment, training data, and model artifacts in under four hours if the AI engineer left tomorrow? If not, what is the cost of that technical debt in deployment delays and risks? | ___ | |
| O2 | What is the weekly dollar loss from unaddressed model drift that goes unnoticed until user reports? | ___ | |
| O3 | What is the timeline for integrating automated monitoring and alerting for business value proxies, not just technical accuracy? | ___ | |
| O4 | Currently, security is a reactive final check. What budget and process will be dedicated to red teaming LLM-powered agents pre-launch, and who is the CISO-aligned contact responsible for mandatory inference-layer security control sign-off? | ___ | |
| O5 | Beyond problem alerting, what is our first agent-driven automation to autonomously manage and redeploy its own model in production (AIOps), in response to a pre-approved data quality trigger? | ___ | |
| O6 | Who owns the A2H (Agent-to-Human) protocol for smart escalation if automation fails? | ___ | |
| O7 | What is our roadmap for implementing a semantic layer or universal governance, making all governed, cleaned data instantly available to any agent or developer, eliminating manual custom feature pipeline creation for new use cases? | ___ | |
| O8 | We can now allocate costs. What is the target cost-per-value metric (e.g., cost per successful claims processed by an agent) we need to achieve, and what automated FinOps agents will we deploy to dynamically scale, compute, and change model sizes to autonomously maintain that metric in real-time? | ___ | |

### Operational & Technical Score

| Metric | Value |
|--------|-------|
| **Total Score** | ___/40 |
| **Average Score** | ___/5 |
| **Phase** | Tactical / Strategic / Transformational |

---

## Overall Assessment Summary

### Aggregate Scores

| Dimension | Score | Average | Phase |
|-----------|-------|---------|-------|
| Vision & Leadership | ___/60 | ___/5 | |
| Talent & Culture | ___/40 | ___/5 | |
| Operational & Technical | ___/40 | ___/5 | |
| **OVERALL** | **___/140** | **___/5** | |

### Phase Determination

| Average Score | Overall Phase |
|---------------|---------------|
| 1.0 - 2.4 | **Tactical** - Ad hoc, siloed, reactive |
| 2.5 - 3.9 | **Strategic** - Centralized, standardized, proactive |
| 4.0 - 5.0 | **Transformational** - Embedded, automated, self-optimizing |

### Dimension Gap Analysis

Identify your highest and lowest scoring dimensions:

| Analysis | Dimension | Score | Priority Action |
|----------|-----------|-------|-----------------|
| **Strongest** | | ___/5 | Leverage as foundation |
| **Weakest** | | ___/5 | Focus improvement here |
| **Most Variance** | | (range) | Align stakeholder understanding |

---

## Worked Example: Cymbal Health

*A fictional healthcare payer system transitioning from Tactical to Strategic phase.*

### Background

Cymbal Health has pockets of exciting but invisible AI work across departments. A new CIO establishes a temporary AI task force to build a clinical note summarizer.

### Sample Assessment

| # | Question | Score | Rationale |
|---|----------|-------|-----------|
| V1 | Top 3 KPIs? | **2** | KPIs identified (claims processing speed) but not formally measured |
| V2 | Error budget? | **1** | No formal error budget exists |
| V3 | Centralized governance? | **2** | CIO task force is temporary, not permanent |
| V4 | Multiyear budget? | **1** | Funding is temporary from CIO discretionary budget |
| V5 | Hiring aligned? | **2** | CIO wants to hire 5 more, but not approved |
| V9 | CEO articulates AI role? | **2** | CEO interested but not actively championing |
| T1 | AI-SME collaboration? | **2** | Data scientists + clinical teams collaborating on pilot |
| T3 | Failed experiments? | **1** | No explicit policy |
| O1 | Knowledge transfer? | **1** | Individual contributors, no documentation |
| O4 | Red teaming? | **1** | Security not involved in AI development |

### Cymbal Health Summary

| Dimension | Average Score | Phase |
|-----------|---------------|-------|
| Vision & Leadership | 1.8 | Late Tactical |
| Talent & Culture | 1.5 | Tactical |
| Operational & Technical | 1.2 | Early Tactical |
| **OVERALL** | **1.5** | **Tactical** |

### Recommendations for Cymbal Health

1. **Vision**: Formalize the AI task force as a permanent Center of Excellence
2. **Talent**: Establish explicit "safe-to-fail" policy for AI experiments
3. **Operations**: Document all AI workflows for knowledge transfer
4. **Next Steps**: See [roadmap_template.md](./roadmap_template.md) for phase transition planning

---

## Next Steps

After completing this assessment:

1. **Review scores** with stakeholders and resolve discrepancies
2. **Consult the rubric** in [maturity_rubric.md](./maturity_rubric.md) for detailed phase descriptions
3. **Identify gaps** between current and target state
4. **Prioritize use cases** with [use_case_mapping.md](./use_case_mapping.md)
5. **Build roadmap** using [roadmap_template.md](./roadmap_template.md)
6. **Reassess** quarterly to track progress

---

## Assessment Metadata

| Field | Value |
|-------|-------|
| **Assessment Date** | _______________ |
| **Lead Assessor** | _______________ |
| **Stakeholders** | _______________ |
| **Next Review Date** | _______________ |
